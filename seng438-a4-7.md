**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group \#:      |   7  |
| -------------- | --- |
|Brenek Spademan               |30060822    |
|Ben Leggett                |30114359     |
|Arion Hamel                |30112662     |
|Jack Rovere                |30085670     |

# Introduction

In assignment 4 we aim to familiarize ourselves with mutation testing and GUI testing through the use of common tools such as Pitest, Selenium IDE, and Sikulix. In contrast to previous assignments, we have no prior experience with either of the testing techniques or their associated tools. 

This assignment has the following objectives:
* Introduce students to mutation testing and GUI testing.
* Give students practice with interpretting mutation scores and utilizing that knowledge to design new test cases.
* Provide students with experience in GUI testing using common tools.

We began by ensuring we grasped the concepts of both testing techniques before exploring the capabilities of the tools provided. Once confident in our understanding of the topics, we used Pitest to run countless generated mutations against our test cases from assignment 3. The resultant statistics guided us as we strengthened our test suite in order to increase our mutation score by 10% in both Range and DataUtilities testing. After a brief discussion on equivalent mutants and ways to detect them, we proceeded to the GUI testing phase of the assignment.

The Selenium IDE was used to design, automate; verify, and execute GUI test cases on the Costco website. We were successful in documenting eight test scripts that can be used to demonstrate functionality on the website. 

Below we go into further detail about our process and findings:

# Analysis of 10 Mutants of the Range class 
<img width="824" alt="Screen Shot 2023-03-15 at 9 33 27 AM" src="https://user-images.githubusercontent.com/101214266/225360703-685c4346-5bed-4dcb-98a3-c702597d548b.png">
As can be seen in picture above there is 10 mutants of getCentralValue where the first four mutants survive and the last six mutants are killed. The first four survive as this.lower/this.upper are incremented/decremented after they are used in the return statement, so it does not affect what the function returns, and as such will not cause a test case to fail. The the last six mutants are killed as they cause what the function returns to change, so they result in test cases failing. 

# Report all the statistics and the mutation score for each test class

<img width="624" alt="image" src="https://user-images.githubusercontent.com/98235387/225403129-57d08aec-52a2-4b69-8a96-e138dca3f7f9.png">

<img width="1065" alt="Screen Shot 2023-03-15 at 9 49 32 AM" src="https://user-images.githubusercontent.com/101214266/225365282-bf9a50d4-d137-4a23-be15-1b8b38ce9bd3.png">

# Analysis drawn on the effectiveness of each of the test classes

The effectiveness of the DataUtilities test suite was originally 73%. This was relatively high, which was a good indicator to us that we had achieved an effective creation of our test case, however it is clear that there was still some room for improvement.

The effectiveness of the Range test suite was originally 61%. This was quite mediocre, which was an indicaton that although our test had achieved high statement and branch coverage, it did not thoroughly test all possible inputs. 

# A discussion on the effect of equivalent mutants on mutation score accuracy

Equivalent mutants are mutants that have no semantic effect on the overall functionality of the code. Because of this, equivalent mutants appear to be an indicator of a fault with the code, when in reality this is untrue. Because of these equivalent mutants, it is basically impossible to achieve 100% mutation coverage. Therefore, it can be said that equivalent mutants have a negative overall effect on mutation score accuracy in a program under test.

__Equivalent Mutants in DataUtilities:__

DataUtilities (Line 104): for (int i = 0; i < source.length; i++) { ------> for (int i = 0; i != source.length; i++) {<br>
DataUtilities (Line 178): for (int c = 0; c < columnCount; c++) { ------> for (int c = 0; c != columnCount; c++) {<br>
DataUtilities (Line 245): for (int i = 0; i < l1; i++) { ------> for (int i = 0; i != l1; i++) {

__Equivalent Mutants in Range:__ 

Range (Line 430): if (!(this.lower == range.lower)) { --> if ((this.lower != range.lower)) { <br>
Range (Line 433): if (!(this.upper == range.upper)) { --> if ((this.upper != range.upper)) { <br>

__How we found equivalent mutations:__

To find equivalent mutations, we looked at the PITEST summary of the files. We checked for all the mutations that survived, because equivalent mutations cannot be killed, as they mimic the correct functionality of the program. When looking at these surviving mutations, we checked the conditions and if they seemed to be equivalent, we tested this functionality manually by changing the code itself (we then changed it back afterwards for consistency).

# A discussion of what could have been done to improve the mutation score of the test suites

It was found that many of the mutations that survived, would have been killed if there was more test cases to test the boundaries of a method. Particularily with the Range class (but also with DataUtilities to a lesser degree), the mutation score was lower as there was many boundary conditions that were not tested. By adding more test cases to test the boundaries of various methods for both classes, more mutations were killed by the test suite. This resulted in the mutation coverage increasing as more boundary value conditions were tested. 

# Mutation Coverage After Changes

__DataUtilities:__<br>

<img width="608" alt="image" src="https://user-images.githubusercontent.com/98235387/225173831-b920ced6-33ec-4e92-8bef-07d1a13d7eda.png">

__Range:__<br>

<img width="1109" alt="Screen Shot 2023-03-15 at 10 19 22 AM" src="https://user-images.githubusercontent.com/101214266/225373772-fd5f1a11-4bcc-4b4f-96c9-2a854f757496.png">

# Why do we need mutation testing? Advantages and disadvantages of mutation testing

Mutation testing is very important in ensuring that the test cases written by software engineers is reliably testing the code, and not just generating a bunch of false positives. Combining a mutation score with line coverage and branch coverage scores helps show a more complete picture of the unit tests being written. For example, if a test suite was built up of test cases that passed on a overly wide range of values, it wouldn't be a good indicator of the program's success as many errors could be perceived by the program as successes. With mutation testing, we can see how strong the test code really is if there are small changes introduced, as a well designed program will be able to react to these relatively discrete mutations with ease.

# Explain your SELENUIM test case design process

<h3> Ben </h3>

__"Add item to cart"__:
The functionality this test is considering is the ability to enter the correct website, browse for an item, and then ad the item to the cart. No functionality following the additon of an item to the cart is tested in this test case. An item is selected from the list of options and then the add-to-cart button is selected. Item browsing is tested using a search for a key-word in the search bar, as well browsing through different catagories starting from the homepage. 

__"Add to cart & Edit cart"__:
The functionality this test is considering is the ability to enter the correct website, browse for an item, and then ad the item to the cart. Next, the cart is opened and the item that was just added to the cart is then removed, updating the contents of the cart. 

<h3> Brenek </h3>

__"Change Country"__:
The functionality this test is considering is the ability to enter the correct website and select a country of origin on the website. Changing from one country to another is the same process regardless of location, so testing once instance where a different country is selected ensures a working system for other country changes. 

__"Change Language"__:
The functionality this test is considering is the ability to enter the correct website and change the language of the site to whatever is desired by the user. The test consdiers altering the French/English language option on the home page, as well as selecting a country with a different language, and seeing if the website updates to the language of the selected country. 

<h3> Arion </h3>

__"testFindLocalWarehouses"__:
The functionality this test is considering is the ability to enter the correct website and display the information related to the closest warehouse. The user will enter Calgary Alberta as their location, and will be able to select "Store Details" in order to view information about the nearest warehouse. We expect the website to find the nearest warehouse's information; an assert title command is used to ensure this outcome has been reached. 

This test was conducted with two different locations in mind: Calgary, AB and Toronto, ON.

Calgary:
![image](https://user-images.githubusercontent.com/99998622/225445273-81db085c-3bf2-4684-aba8-2452a2f4a1ea.png)

Toronto:

![image](https://user-images.githubusercontent.com/99998622/225445344-19941c1c-9fe3-4bcd-a35c-54ea1eb70c5c.png)

__"testSignOut"__:
The functionality this test is considering is the ability to enter the correct website and attempt to sign out of a registered account. This test must be conducted while the user is signed in, thus an assert text command ensures that the user is signed in. We expect the website to sucessfully logout a user and return us to the home page, which is verified with an assert title command.

![image](https://user-images.githubusercontent.com/99998622/225445404-f4e8a8eb-9d48-469b-9902-e1ad23813b56.png)


<h3> Jack </h3>

__"testLoginInvalidUser"__:
The functionality this test is considering is the ability to enter the correct website and attempt to login with incorrect information. This test is utilized to run the login test with different test data. An assert text command is used to ensure that the user is not already logged in. We expect the website to demonstrate that a login was unsuccessful because the user entered incorrect data, and an assert title command is used to verify this outcome. 

![image](https://user-images.githubusercontent.com/99998622/225445457-6d3e1b72-f9de-4bab-b181-cb7a1cd849ab.png)

__"testLoginValidUser"__:
The functionaity this test is considering is the ability to enter the correct website and attempt to login with correct information. This test is utilized to run the login test with different test data. An assert text command is used to ensure that the user is not already logged in.  We expect the website to demonstrate that a login was sucessful and an assert title command is used to verify this outcome.

![image](https://user-images.githubusercontent.com/99998622/225445498-4f4d33d6-2ae8-4d87-a6db-b0438921d3e3.png)

As expected accross all of our GUI tests, no defects were found in any of the functionality tested. 

# Explain the use of assertions and checkpoints

Assertions and checkpoints were used throughout our test cases to ensure the test conditions, as well as validate the outcomes of each test. We use commands such as assert text or verify title to establish certain requirements of our SUT in order to pass the current test. 

# how did you test each functionaity with different test data
__"Add item to cart"__:
The functionality of adding an item to the cart ws tested by selecting different items from various catagories of products on the website to the cart. The user chooses to either select the "add to cart" button or not, and so to ensure this funciton  is consistant, different items and their ability to be added were considered.  

__"Add to cart & Edit cart"__:
The functionality of adding products to the cart and then editing the cart was tested by selcting differet products, adding to the cart, and then removing them. This was accomplished with different test data by selecting and removing different types of products. 

__"Change Country"__:
The functionality of changing the location setting of the website was accomplished by selecting different countires from the dropdown menu. Changing countries from one to another is the same process of selecting a different country than currently selected from the dropdown menu, and so only one instance of changing countries was tested. 

__"Change Language"__:
The functionality of changing the language setting of the website was accomplished by selecting different countires from the dropdown menu and observing the updated change to the local language, and switching between the choices of 'French/English' on the home page. Changing languages from one to another by changing countries has an identical process regardless of what country is selected, and the choosing between french and english from the homepage is similiar in that it is simply a choice of one or the other with a single process. So, one instance of changing countries was tested, and the changing of french to english and english to french were tested as differing inputs.  

__"testFindLocalWarehouses"__:
The funcitonality of locating a local warehouse was tested by inputting a location and displaying the nearest warehouses' data. This was accomplished with different test data via inputting two locations - Calgary, Alberta and Toronto, Ontario.

__"testLogin"__:
The funcitonality of logging into the website was tested by inputting a username and password. This was accomplished with different test data via inputting an incorrect and correct set of data, resulting in two possible outcomes to the login function.

# Discuss advantages and disadvantages of Selenium vs. Sikulix

Selenium was quite easy to use and learn, with support across multiple browsers. However there seemed to be limited functionality, as each assertion and checkpoint in our test scripts needed to be manually inputted. In comparison, Sikulix was complex and had a steep learning curve, yet more robust in automating UI interactions, allowing us to create deeper and more fleshed out testing scripts.

# How the team work/effort was divided and managed

For the mutation testing part of this lab, Brenek and Ben worked on the Range class while Jack and Arion worked on DataUtilities. For the GUI testing portion of this lab, we all worked together to ensure we had developed different test cases, and that we all understood how to use both Selenium and Sikulix.

# Difficulties encountered, challenges overcome, and lessons learned

A diffuculty encountered in this lab was figuring out how to improve our mutation coverage, so that more mutations would be killed. This challenge was overcome by discovering that many of the surviving mutants survived because boundary conditions were not tested. Through this lab we learned the importance of testing boundary conditions.

# Comments/feedback on the lab itself

This lab we very enjoyable, and we all felt that it helped to prepare us for the course final, as we improved our understanding of mutation and GUI testing.


